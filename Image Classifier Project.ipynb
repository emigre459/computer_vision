{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE TO THE GRADER: at this point, I should mention that I had to update the `pytorch` and `torchvision` packages in the Udacity GPU workspace to make my model train properly.** For some reason, the training output was coming out as a tuple of tensors instead of as an InceptionOutputs object. Once I updated these packages and the `cudatoolkit` from v8 to v9, everything started training well again.\n",
    "\n",
    "Did this by opening a new terminal window and running `conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T01:41:42.455555Z",
     "start_time": "2019-06-07T01:41:42.450394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T14:37:32.819553Z",
     "start_time": "2019-06-06T14:37:32.816016Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T05:03:30.649466Z",
     "start_time": "2019-05-31T05:03:30.573605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "\n",
    "# Means and stdevs common for pre-trained networks\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stdevs = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Inception V3 uses 299x299 images as inputs, not the standard 224x224 of other models\n",
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "                                       transforms.ColorJitter(brightness=0.15, \n",
    "                                                              contrast=0.15, \n",
    "                                                              saturation=0.15, \n",
    "                                                              hue=0),\n",
    "                                       transforms.RandomAffine(30),\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(means, \n",
    "                                                            stdevs)])\n",
    "\n",
    "\n",
    "# Data augmentation doesn't get applied to val or test sets\n",
    "validation_transforms = transforms.Compose([transforms.Resize(512),\n",
    "                                            transforms.CenterCrop(299),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(means,\n",
    "                                                                 stdevs)])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(512),\n",
    "                                      transforms.CenterCrop(299),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(means, \n",
    "                                                            stdevs)])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T02:46:18.834336Z",
     "start_time": "2019-06-07T02:46:18.825859Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21': 'fire lily',\n",
       " '3': 'canterbury bells',\n",
       " '45': 'bolero deep blue',\n",
       " '1': 'pink primrose',\n",
       " '34': 'mexican aster',\n",
       " '27': 'prince of wales feathers',\n",
       " '7': 'moon orchid',\n",
       " '16': 'globe-flower',\n",
       " '25': 'grape hyacinth',\n",
       " '26': 'corn poppy',\n",
       " '79': 'toad lily',\n",
       " '39': 'siam tulip',\n",
       " '24': 'red ginger',\n",
       " '67': 'spring crocus',\n",
       " '35': 'alpine sea holly',\n",
       " '32': 'garden phlox',\n",
       " '10': 'globe thistle',\n",
       " '6': 'tiger lily',\n",
       " '93': 'ball moss',\n",
       " '33': 'love in the mist',\n",
       " '9': 'monkshood',\n",
       " '102': 'blackberry lily',\n",
       " '14': 'spear thistle',\n",
       " '19': 'balloon flower',\n",
       " '100': 'blanket flower',\n",
       " '13': 'king protea',\n",
       " '49': 'oxeye daisy',\n",
       " '15': 'yellow iris',\n",
       " '61': 'cautleya spicata',\n",
       " '31': 'carnation',\n",
       " '64': 'silverbush',\n",
       " '68': 'bearded iris',\n",
       " '63': 'black-eyed susan',\n",
       " '69': 'windflower',\n",
       " '62': 'japanese anemone',\n",
       " '20': 'giant white arum lily',\n",
       " '38': 'great masterwort',\n",
       " '4': 'sweet pea',\n",
       " '86': 'tree mallow',\n",
       " '101': 'trumpet creeper',\n",
       " '42': 'daffodil',\n",
       " '22': 'pincushion flower',\n",
       " '2': 'hard-leaved pocket orchid',\n",
       " '54': 'sunflower',\n",
       " '66': 'osteospermum',\n",
       " '70': 'tree poppy',\n",
       " '85': 'desert-rose',\n",
       " '99': 'bromelia',\n",
       " '87': 'magnolia',\n",
       " '5': 'english marigold',\n",
       " '92': 'bee balm',\n",
       " '28': 'stemless gentian',\n",
       " '97': 'mallow',\n",
       " '57': 'gaura',\n",
       " '40': 'lenten rose',\n",
       " '47': 'marigold',\n",
       " '59': 'orange dahlia',\n",
       " '48': 'buttercup',\n",
       " '55': 'pelargonium',\n",
       " '36': 'ruby-lipped cattleya',\n",
       " '91': 'hippeastrum',\n",
       " '29': 'artichoke',\n",
       " '71': 'gazania',\n",
       " '90': 'canna lily',\n",
       " '18': 'peruvian lily',\n",
       " '98': 'mexican petunia',\n",
       " '8': 'bird of paradise',\n",
       " '30': 'sweet william',\n",
       " '17': 'purple coneflower',\n",
       " '52': 'wild pansy',\n",
       " '84': 'columbine',\n",
       " '12': \"colt's foot\",\n",
       " '11': 'snapdragon',\n",
       " '96': 'camellia',\n",
       " '23': 'fritillary',\n",
       " '50': 'common dandelion',\n",
       " '44': 'poinsettia',\n",
       " '53': 'primula',\n",
       " '72': 'azalea',\n",
       " '65': 'californian poppy',\n",
       " '80': 'anthurium',\n",
       " '76': 'morning glory',\n",
       " '37': 'cape flower',\n",
       " '56': 'bishop of llandaff',\n",
       " '60': 'pink-yellow dahlia',\n",
       " '82': 'clematis',\n",
       " '58': 'geranium',\n",
       " '75': 'thorn apple',\n",
       " '41': 'barbeton daisy',\n",
       " '95': 'bougainvillea',\n",
       " '43': 'sword lily',\n",
       " '83': 'hibiscus',\n",
       " '78': 'lotus lotus',\n",
       " '88': 'cyclamen',\n",
       " '94': 'foxglove',\n",
       " '81': 'frangipani',\n",
       " '74': 'rose',\n",
       " '89': 'watercress',\n",
       " '73': 'water lily',\n",
       " '46': 'wallflower',\n",
       " '77': 'passion flower',\n",
       " '51': 'petunia'}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    \n",
    "cat_to_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to\n",
    "GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module.\n",
    "\n",
    "**Note for Workspace users:** If your network is over 1 GB when saved as a checkpoint, there might be issues with saving backups in your workspace. Typically this happens with wide dense layers after the convolutional layers. If your saved checkpoint is larger than 1 GB (you can open a terminal and check with `ls -lh`), you should reduce the size of your hidden layers and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T03:15:32.106798Z",
     "start_time": "2019-06-03T03:15:29.225304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
      "100%|██████████| 108857766/108857766 [00:05<00:00, 21022338.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T03:15:37.102158Z",
     "start_time": "2019-06-03T03:15:37.097530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through the pre-trained feature detector\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T03:15:40.575541Z",
     "start_time": "2019-06-03T03:15:40.543923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (dropout1): Dropout(p=0.2)\n",
       "  (hidden2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (dropout2): Dropout(p=0.2)\n",
       "  (hidden3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (activation3): ReLU()\n",
       "  (output): Linear(in_features=256, out_features=102, bias=True)\n",
       "  (activation_output): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup new (relatively shallow) classifer network\n",
    "from collections import OrderedDict\n",
    "\n",
    "layers = OrderedDict([('hidden1', nn.Linear(2048, 1024)),\n",
    "                      ('activation1', nn.ReLU()),\n",
    "                      ('dropout1', nn.Dropout(p=0.2)),\n",
    "                      ('hidden2', nn.Linear(1024, 512)),\n",
    "                      ('activation2', nn.ReLU()),\n",
    "                      ('dropout2', nn.Dropout(p=0.2)),\n",
    "                      ('hidden3', nn.Linear(512, 256)),\n",
    "                      ('activation3', nn.ReLU()),\n",
    "                      ('output', nn.Linear(256, 102)),\n",
    "                      ('activation_output', nn.LogSoftmax(dim=1))])\n",
    "\n",
    "classifier = nn.Sequential(layers)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T03:22:49.602160Z",
     "start_time": "2019-06-03T03:22:49.587811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (hidden1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (activation1): ReLU()\n",
       "    (dropout1): Dropout(p=0.2)\n",
       "    (hidden2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (activation2): ReLU()\n",
       "    (dropout2): Dropout(p=0.2)\n",
       "    (hidden3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (activation3): ReLU()\n",
       "    (output): Linear(in_features=256, out_features=102, bias=True)\n",
       "    (activation_output): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the classifier of our pre-trained model to be our new classifier\n",
    "# which does NOT have requires_grad = False and thus can be trained,\n",
    "# unlike our feature detector network\n",
    "model.fc = classifier\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T03:23:11.414272Z",
     "start_time": "2019-06-03T03:23:11.402610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If GPU is enabled, set device = 'cuda'. Otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Actual loss function dictated by model architecture, of course\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0005)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "\n",
    "1. Integrate the code below for keeping track of your best epoch and using its weights in the end\n",
    "    * Make sure to load the `best_model_wts` state_dict to your model at the end of all epochs\n",
    "2. Add one or more hidden layers to your existing classifier (I'd recommend at least two more) and some more aggressive dropout (let's double it to `p=0.4`) to see if we can improve training significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: keep track of the best accuracy in all of your epochs and reload the state_dict of that one\n",
    "# at the end\n",
    "# Code for this from https://medium.com/datadriveninvestor/creating-a-pytorch-image-classifier-da9db139ba80\n",
    "\n",
    "# Before first epoch\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# After validation loop in a given epoch\n",
    "if accuracy > best_accuracy:\n",
    "    best_accuracy = accuracy\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T12:46:22.560063Z",
     "start_time": "2019-06-03T12:45:46.430333Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 0\n",
      "Loss =             4.630075931549072\n",
      "\n",
      "Training batch 10\n",
      "Loss =             4.599021651528099\n",
      "\n",
      "Training batch 20\n",
      "Loss =             4.587151209513347\n",
      "\n",
      "Training batch 30\n",
      "Loss =             4.5677551607931814\n",
      "\n",
      "Training batch 40\n",
      "Loss =             4.554961239419332\n",
      "\n",
      "Training batch 50\n",
      "Loss =             4.540976645899754\n",
      "\n",
      "Training batch 60\n",
      "Loss =             4.525427685409296\n",
      "\n",
      "Training batch 70\n",
      "Loss =             4.505955897586446\n",
      "\n",
      "Training batch 80\n",
      "Loss =             4.48654908898436\n",
      "\n",
      "Training batch 90\n",
      "Loss =             4.464908081096607\n",
      "\n",
      "Training batch 100\n",
      "Loss =             4.435434981147842\n",
      "\n",
      "Training batch 102\n",
      "Loss =             4.427963423497468\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       4.709080219268799\n",
      " and                       accuracy = 0.0\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       4.4813215136528015\n",
      " and                       accuracy = 0.0078125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       4.143697363989694\n",
      " and                       accuracy = 0.06696428571428571\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       3.968656849861145\n",
      " and                       accuracy = 0.1015625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       3.9601258497971754\n",
      " and                       accuracy = 0.10971153842715117\n",
      "\n",
      "For epoch 1/30...\n",
      "3.106 minutes since training started\n",
      "Training loss = 4.427963423497468\n",
      "Validation loss = 3.9601258497971754\n",
      "Accuracy = 0.10971153842715117\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             4.313668251037598\n",
      "\n",
      "Training batch 10\n",
      "Loss =             4.0214713703502305\n",
      "\n",
      "Training batch 20\n",
      "Loss =             3.9770463080633256\n",
      "\n",
      "Training batch 30\n",
      "Loss =             3.8839703913657897\n",
      "\n",
      "Training batch 40\n",
      "Loss =             3.845642206145496\n",
      "\n",
      "Training batch 50\n",
      "Loss =             3.8027920115227793\n",
      "\n",
      "Training batch 60\n",
      "Loss =             3.7431656884365396\n",
      "\n",
      "Training batch 70\n",
      "Loss =             3.714810895248198\n",
      "\n",
      "Training batch 80\n",
      "Loss =             3.6785220746640808\n",
      "\n",
      "Training batch 90\n",
      "Loss =             3.642503557624398\n",
      "\n",
      "Training batch 100\n",
      "Loss =             3.5944703427871856\n",
      "\n",
      "Training batch 102\n",
      "Loss =             3.584812094864336\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       3.4474098682403564\n",
      " and                       accuracy = 0.09375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       3.429236352443695\n",
      " and                       accuracy = 0.1328125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       3.0161166531699046\n",
      " and                       accuracy = 0.25223214285714285\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       2.8765815258026124\n",
      " and                       accuracy = 0.2875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       2.9706387519836426\n",
      " and                       accuracy = 0.2717307691390698\n",
      "\n",
      "For epoch 2/30...\n",
      "5.965 minutes since training started\n",
      "Training loss = 3.584812094864336\n",
      "Validation loss = 2.9706387519836426\n",
      "Accuracy = 0.2717307691390698\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             2.8060503005981445\n",
      "\n",
      "Training batch 10\n",
      "Loss =             3.0560822703621606\n",
      "\n",
      "Training batch 20\n",
      "Loss =             3.0485755602518716\n",
      "\n",
      "Training batch 30\n",
      "Loss =             3.0474659704392955\n",
      "\n",
      "Training batch 40\n",
      "Loss =             3.0313705758350653\n",
      "\n",
      "Training batch 50\n",
      "Loss =             3.0105524764341465\n",
      "\n",
      "Training batch 60\n",
      "Loss =             2.977411461658165\n",
      "\n",
      "Training batch 70\n",
      "Loss =             2.9625112607445514\n",
      "\n",
      "Training batch 80\n",
      "Loss =             2.9361638169229765\n",
      "\n",
      "Training batch 90\n",
      "Loss =             2.92661782673427\n",
      "\n",
      "Training batch 100\n",
      "Loss =             2.8965237305896117\n",
      "\n",
      "Training batch 102\n",
      "Loss =             2.8935054135554044\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       2.941279888153076\n",
      " and                       accuracy = 0.109375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       2.688614010810852\n",
      " and                       accuracy = 0.25390625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       2.4049004146030972\n",
      " and                       accuracy = 0.35267857142857145\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       2.1785202622413635\n",
      " and                       accuracy = 0.41875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       2.2906497166706967\n",
      " and                       accuracy = 0.40754807683137745\n",
      "\n",
      "For epoch 3/30...\n",
      "8.826 minutes since training started\n",
      "Training loss = 2.8935054135554044\n",
      "Validation loss = 2.2906497166706967\n",
      "Accuracy = 0.40754807683137745\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             2.7447409629821777\n",
      "\n",
      "Training batch 10\n",
      "Loss =             2.6124897219917993\n",
      "\n",
      "Training batch 20\n",
      "Loss =             2.5549060163043795\n",
      "\n",
      "Training batch 30\n",
      "Loss =             2.5954529085466937\n",
      "\n",
      "Training batch 40\n",
      "Loss =             2.6182411414820974\n",
      "\n",
      "Training batch 50\n",
      "Loss =             2.6197494151545504\n",
      "\n",
      "Training batch 60\n",
      "Loss =             2.612156668647391\n",
      "\n",
      "Training batch 70\n",
      "Loss =             2.6073369408997014\n",
      "\n",
      "Training batch 80\n",
      "Loss =             2.5954406290878484\n",
      "\n",
      "Training batch 90\n",
      "Loss =             2.5728707313537598\n",
      "\n",
      "Training batch 100\n",
      "Loss =             2.551906153707221\n",
      "\n",
      "Training batch 102\n",
      "Loss =             2.549920281160225\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       2.18684720993042\n",
      " and                       accuracy = 0.296875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       2.1243563890457153\n",
      " and                       accuracy = 0.40234375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.825803586414882\n",
      " and                       accuracy = 0.5\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.7123276591300964\n",
      " and                       accuracy = 0.540625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.8413248337232149\n",
      " and                       accuracy = 0.5091346158431127\n",
      "\n",
      "For epoch 4/30...\n",
      "11.682 minutes since training started\n",
      "Training loss = 2.549920281160225\n",
      "Validation loss = 1.8413248337232149\n",
      "Accuracy = 0.5091346158431127\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             2.354867458343506\n",
      "\n",
      "Training batch 10\n",
      "Loss =             2.392130071466619\n",
      "\n",
      "Training batch 20\n",
      "Loss =             2.3700498456046697\n",
      "\n",
      "Training batch 30\n",
      "Loss =             2.3576152824586436\n",
      "\n",
      "Training batch 40\n",
      "Loss =             2.33509830439963\n",
      "\n",
      "Training batch 50\n",
      "Loss =             2.338735211129282\n",
      "\n",
      "Training batch 60\n",
      "Loss =             2.3161679916694515\n",
      "\n",
      "Training batch 70\n",
      "Loss =             2.2994210787222418\n",
      "\n",
      "Training batch 80\n",
      "Loss =             2.284774402041494\n",
      "\n",
      "Training batch 90\n",
      "Loss =             2.2842454189782613\n",
      "\n",
      "Training batch 100\n",
      "Loss =             2.284429453387119\n",
      "\n",
      "Training batch 102\n",
      "Loss =             2.2838104141568674\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       2.04996919631958\n",
      " and                       accuracy = 0.390625\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.9405666589736938\n",
      " and                       accuracy = 0.4921875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.7284181118011475\n",
      " and                       accuracy = 0.5334821428571429\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.6346226751804351\n",
      " and                       accuracy = 0.5671875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.7532993417519789\n",
      " and                       accuracy = 0.5491346143759214\n",
      "\n",
      "For epoch 5/30...\n",
      "14.544 minutes since training started\n",
      "Training loss = 2.2838104141568674\n",
      "Validation loss = 1.7532993417519789\n",
      "Accuracy = 0.5491346143759214\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.9770056009292603\n",
      "\n",
      "Training batch 10\n",
      "Loss =             2.1317026940259067\n",
      "\n",
      "Training batch 20\n",
      "Loss =             2.173600367137364\n",
      "\n",
      "Training batch 30\n",
      "Loss =             2.1430140618355042\n",
      "\n",
      "Training batch 40\n",
      "Loss =             2.153241739040468\n",
      "\n",
      "Training batch 50\n",
      "Loss =             2.129895441672381\n",
      "\n",
      "Training batch 60\n",
      "Loss =             2.121469769321504\n",
      "\n",
      "Training batch 70\n",
      "Loss =             2.120864324166741\n",
      "\n",
      "Training batch 80\n",
      "Loss =             2.114424517125259\n",
      "\n",
      "Training batch 90\n",
      "Loss =             2.112915264381157\n",
      "\n",
      "Training batch 100\n",
      "Loss =             2.096629570026209\n",
      "\n",
      "Training batch 102\n",
      "Loss =             2.0972759700515895\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.5626862049102783\n",
      " and                       accuracy = 0.515625\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.569919377565384\n",
      " and                       accuracy = 0.5625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.400935070855277\n",
      " and                       accuracy = 0.6205357142857143\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.2988509356975555\n",
      " and                       accuracy = 0.6625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation batch 12\n",
      "Loss =                       1.497193836248838\n",
      " and                       accuracy = 0.6151923078757066\n",
      "\n",
      "For epoch 6/30...\n",
      "17.399 minutes since training started\n",
      "Training loss = 2.0972759700515895\n",
      "Validation loss = 1.497193836248838\n",
      "Accuracy = 0.6151923078757066\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             2.002833843231201\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.9812714511697942\n",
      "\n",
      "Training batch 20\n",
      "Loss =             2.0507045473371233\n",
      "\n",
      "Training batch 30\n",
      "Loss =             2.055511220808952\n",
      "\n",
      "Training batch 40\n",
      "Loss =             2.0179061860573\n",
      "\n",
      "Training batch 50\n",
      "Loss =             2.036121723698635\n",
      "\n",
      "Training batch 60\n",
      "Loss =             2.027010003074271\n",
      "\n",
      "Training batch 70\n",
      "Loss =             2.005722806487285\n",
      "\n",
      "Training batch 80\n",
      "Loss =             2.0017976216327997\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.9893886401103094\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.990009872039946\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.9909755396611482\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.5991309881210327\n",
      " and                       accuracy = 0.546875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.5083418786525726\n",
      " and                       accuracy = 0.5859375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.352534328188215\n",
      " and                       accuracy = 0.6205357142857143\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.1786017060279845\n",
      " and                       accuracy = 0.690625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.3594548610540538\n",
      " and                       accuracy = 0.6375480775649731\n",
      "\n",
      "For epoch 7/30...\n",
      "20.261 minutes since training started\n",
      "Training loss = 1.9909755396611482\n",
      "Validation loss = 1.3594548610540538\n",
      "Accuracy = 0.6375480775649731\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.8470723628997803\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.8117120916193181\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.879163730712164\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.9197594504202566\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.910178510154166\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.9103284489874746\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.898131929460119\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.884626655511453\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.8904835177056583\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.878362924188048\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.874842076018305\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.8809358795869697\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.5261847972869873\n",
      " and                       accuracy = 0.5625\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.5084851831197739\n",
      " and                       accuracy = 0.58203125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.3086259365081787\n",
      " and                       accuracy = 0.640625\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.194481724500656\n",
      " and                       accuracy = 0.678125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.3442792754906874\n",
      " and                       accuracy = 0.6269230773815742\n",
      "\n",
      "For epoch 8/30...\n",
      "23.121 minutes since training started\n",
      "Training loss = 1.8809358795869697\n",
      "Validation loss = 1.3442792754906874\n",
      "Accuracy = 0.6269230773815742\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.7281768321990967\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.8450541496276855\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.8568231491815477\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.8267287823461718\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.8157684512254668\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.7932545577778536\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.8116539091360373\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.8229582460833267\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.8226100986386522\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.8212633421132853\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.8226092581701752\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.8222489009783105\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.378002643585205\n",
      " and                       accuracy = 0.53125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.342108353972435\n",
      " and                       accuracy = 0.61328125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.1697454367365157\n",
      " and                       accuracy = 0.6785714285714286\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.0860553562641144\n",
      " and                       accuracy = 0.715625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.2439942772571857\n",
      " and                       accuracy = 0.6788942309526297\n",
      "\n",
      "For epoch 9/30...\n",
      "25.983 minutes since training started\n",
      "Training loss = 1.8222489009783105\n",
      "Validation loss = 1.2439942772571857\n",
      "Accuracy = 0.6788942309526297\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.7618106603622437\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.8016361648386174\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.7931778658004034\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.7413614411507883\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.752615980985688\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.7276307461308498\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.7230579110442614\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.7352022587413518\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.7405627568562825\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.739679360127711\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.7297235538463782\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.7281363068275082\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.1720186471939087\n",
      " and                       accuracy = 0.6875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.2684202939271927\n",
      " and                       accuracy = 0.65625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.1389636056763786\n",
      " and                       accuracy = 0.6897321428571429\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.030676108598709\n",
      " and                       accuracy = 0.734375\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.1706111843769367\n",
      " and                       accuracy = 0.6871634607131665\n",
      "\n",
      "For epoch 10/30...\n",
      "28.838 minutes since training started\n",
      "Training loss = 1.7281363068275082\n",
      "Validation loss = 1.1706111843769367\n",
      "Accuracy = 0.6871634607131665\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.9350636005401611\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.757498643615029\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.7141972099031721\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.7054668703386862\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.6999535444306164\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.6986745806301342\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.694548259015943\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.679224904154388\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.6745596402957115\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.6792064682467953\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.6824834181530641\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.677565723946951\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.3653846979141235\n",
      " and                       accuracy = 0.609375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.2245969772338867\n",
      " and                       accuracy = 0.671875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.17317134141922\n",
      " and                       accuracy = 0.6830357142857143\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       1.0480313301086426\n",
      " and                       accuracy = 0.7328125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.1803490657072802\n",
      " and                       accuracy = 0.7068749987162076\n",
      "\n",
      "For epoch 11/30...\n",
      "31.699 minutes since training started\n",
      "Training loss = 1.677565723946951\n",
      "Validation loss = 1.1803490657072802\n",
      "Accuracy = 0.7068749987162076\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.823232889175415\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.6167688153006814\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.6174463374274117\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.6010769528727378\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.631448300873361\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.639490244435329\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.615972737796971\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.6130451669155712\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.6096267523588959\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.6058326658311781\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.5980640213088233\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.5992474197184\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.3146244287490845\n",
      " and                       accuracy = 0.609375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation batch 3\n",
      "Loss =                       1.2427371889352798\n",
      " and                       accuracy = 0.65625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       1.130999505519867\n",
      " and                       accuracy = 0.6852678571428571\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.9889650374650956\n",
      " and                       accuracy = 0.7296875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.108177003952173\n",
      " and                       accuracy = 0.7003365388283362\n",
      "\n",
      "For epoch 12/30...\n",
      "34.563 minutes since training started\n",
      "Training loss = 1.5992474197184\n",
      "Validation loss = 1.108177003952173\n",
      "Accuracy = 0.7003365388283362\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.580733060836792\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.6144718690352007\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.544016162554423\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.5710592885171213\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.544004425769899\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.5332859123454374\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.5545505480688127\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.557997226715088\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.5502789005821134\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.562001448411208\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.5663412608722649\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.5676462407251006\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.035827875137329\n",
      " and                       accuracy = 0.671875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.0858712643384933\n",
      " and                       accuracy = 0.703125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.9899256910596576\n",
      " and                       accuracy = 0.7455357142857143\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.916696098446846\n",
      " and                       accuracy = 0.7609375\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       1.044167392528974\n",
      " and                       accuracy = 0.7291826926744901\n",
      "\n",
      "For epoch 13/30...\n",
      "37.428 minutes since training started\n",
      "Training loss = 1.5676462407251006\n",
      "Validation loss = 1.044167392528974\n",
      "Accuracy = 0.7291826926744901\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.57078218460083\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.4400159879164263\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.505095056125096\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.5382996989834694\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.5651477749754743\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.5668494140400606\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.5687692829819977\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.5657418143581336\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.5631023203885113\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.5659715159908756\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.5602789857599995\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.5629013336977913\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.8820058107376099\n",
      " and                       accuracy = 0.765625\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.0792687237262726\n",
      " and                       accuracy = 0.72265625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.9505730271339417\n",
      " and                       accuracy = 0.75\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.8694554954767227\n",
      " and                       accuracy = 0.7765625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9884048264760238\n",
      " and                       accuracy = 0.746875001833989\n",
      "\n",
      "For epoch 14/30...\n",
      "40.292 minutes since training started\n",
      "Training loss = 1.5629013336977913\n",
      "Validation loss = 0.9884048264760238\n",
      "Accuracy = 0.746875001833989\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.6506805419921875\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.6448945132168857\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.5642615755399067\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.5522706027953856\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.5414928706680857\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.5387101605826734\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.536318850321848\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.540904789743289\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.5327083012204112\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.5237709421377916\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.5213277204201954\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.519360746573476\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.0001959800720215\n",
      " and                       accuracy = 0.703125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.0817234218120575\n",
      " and                       accuracy = 0.6953125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.9656315190451485\n",
      " and                       accuracy = 0.734375\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.8394967824220657\n",
      " and                       accuracy = 0.7828125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9523433194710658\n",
      " and                       accuracy = 0.7674519236271198\n",
      "\n",
      "For epoch 15/30...\n",
      "43.151 minutes since training started\n",
      "Training loss = 1.519360746573476\n",
      "Validation loss = 0.9523433194710658\n",
      "Accuracy = 0.7674519236271198\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.4445027112960815\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.580358537760648\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.5657404945010232\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.5635866849653182\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.5850837812191103\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.5772512636932672\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.5638178762842396\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.559878324119138\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.5492807891633775\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.533133673143911\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.521256734829138\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.5130731596530063\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.9982450008392334\n",
      " and                       accuracy = 0.796875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.1232492625713348\n",
      " and                       accuracy = 0.71875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.8868947114263263\n",
      " and                       accuracy = 0.7723214285714286\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.8110402226448059\n",
      " and                       accuracy = 0.7890625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9332944429837741\n",
      " and                       accuracy = 0.7623076943250803\n",
      "\n",
      "For epoch 16/30...\n",
      "46.012 minutes since training started\n",
      "Training loss = 1.5130731596530063\n",
      "Validation loss = 0.9332944429837741\n",
      "Accuracy = 0.7623076943250803\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.5259183645248413\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.3985731168226763\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.4492286216645014\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.4609248445880028\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.4604471165959427\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.5028148959664738\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.4976592767434043\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.5011608130495313\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.4862332167448822\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.479570121555538\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.4848675786858738\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.4812755191210405\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.835294246673584\n",
      " and                       accuracy = 0.78125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.0216436684131622\n",
      " and                       accuracy = 0.7109375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.9130565524101257\n",
      " and                       accuracy = 0.7477678571428571\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.7996768563985824\n",
      " and                       accuracy = 0.7921875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.944127273101073\n",
      " and                       accuracy = 0.7604326926744901\n",
      "\n",
      "For epoch 17/30...\n",
      "48.882 minutes since training started\n",
      "Training loss = 1.4812755191210405\n",
      "Validation loss = 0.944127273101073\n",
      "Accuracy = 0.7604326926744901\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.576365351676941\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.4470679651607166\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.4284285704294841\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.4333154616817352\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.4173707496829149\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.404129472433352\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.4047641500097807\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 70\n",
      "Loss =             1.417235941954062\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.4168154604641008\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.4238796535429064\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.434169311334591\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.4341419692178374\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       1.0316720008850098\n",
      " and                       accuracy = 0.703125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       1.0591673254966736\n",
      " and                       accuracy = 0.73046875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.931074150971004\n",
      " and                       accuracy = 0.7544642857142857\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.8436983793973922\n",
      " and                       accuracy = 0.7921875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9796542364817399\n",
      " and                       accuracy = 0.7575480754558856\n",
      "\n",
      "For epoch 18/30...\n",
      "51.737 minutes since training started\n",
      "Training loss = 1.4341419692178374\n",
      "Validation loss = 0.9796542364817399\n",
      "Accuracy = 0.7575480754558856\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.239411473274231\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.3519562591205945\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.355867394379207\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.3819514109242348\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.4065568897782303\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.386270585013371\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.374169458131321\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3713554874272413\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.3748540458855805\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.377996014369713\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.3867657615406679\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.3846147471261256\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.6978472471237183\n",
      " and                       accuracy = 0.84375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8878920525312424\n",
      " and                       accuracy = 0.7578125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.8139340877532959\n",
      " and                       accuracy = 0.7745535714285714\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.7580770432949067\n",
      " and                       accuracy = 0.8078125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9026913046836853\n",
      " and                       accuracy = 0.7779326943250803\n",
      "\n",
      "For epoch 19/30...\n",
      "54.596 minutes since training started\n",
      "Training loss = 1.3846147471261256\n",
      "Validation loss = 0.9026913046836853\n",
      "Accuracy = 0.7779326943250803\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.340595006942749\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.4061647003347224\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.4713736034574962\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.4466419143061484\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.4444716151167707\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.4385672153211106\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.4252566226193162\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.4262588620185852\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.4164239955537112\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.4107532442271054\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.4188828308983605\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.4190193050116011\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.799330472946167\n",
      " and                       accuracy = 0.796875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.9569751173257828\n",
      " and                       accuracy = 0.73046875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.8484788877623421\n",
      " and                       accuracy = 0.7611607142857143\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.7705819338560105\n",
      " and                       accuracy = 0.7875\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.8867352627790891\n",
      " and                       accuracy = 0.7645673064085153\n",
      "\n",
      "For epoch 20/30...\n",
      "57.456 minutes since training started\n",
      "Training loss = 1.4190193050116011\n",
      "Validation loss = 0.8867352627790891\n",
      "Accuracy = 0.7645673064085153\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.6103683710098267\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.425902865149758\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.3879933470771426\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.411214328581287\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.4195397307233113\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.441977115238414\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.453624912949859\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.4331188151534175\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.4349261713616641\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.4304945665401416\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.425360097743497\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.4231823497605556\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.7581304907798767\n",
      " and                       accuracy = 0.78125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8835710436105728\n",
      " and                       accuracy = 0.75390625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.8676715237753732\n",
      " and                       accuracy = 0.7544642857142857\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.7815382361412049\n",
      " and                       accuracy = 0.784375\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.9242696211888239\n",
      " and                       accuracy = 0.7482692324198209\n",
      "\n",
      "For epoch 21/30...\n",
      "60.311 minutes since training started\n",
      "Training loss = 1.4231823497605556\n",
      "Validation loss = 0.9242696211888239\n",
      "Accuracy = 0.7482692324198209\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.2734615802764893\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.3594387444582852\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.3921200320834206\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.393983648669335\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.3901901274192623\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.378089140443241\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.3765356423424893\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3808011068424708\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.384172099607962\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.3861782105414422\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.3772612786529088\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.3690901855820592\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.67600417137146\n",
      " and                       accuracy = 0.859375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8881308287382126\n",
      " and                       accuracy = 0.77734375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.765834024974278\n",
      " and                       accuracy = 0.8058035714285714\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.683757609128952\n",
      " and                       accuracy = 0.825\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.8021697677098788\n",
      " and                       accuracy = 0.8011057697809659\n",
      "\n",
      "For epoch 22/30...\n",
      "63.167 minutes since training started\n",
      "Training loss = 1.3690901855820592\n",
      "Validation loss = 0.8021697677098788\n",
      "Accuracy = 0.8011057697809659\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.0182522535324097\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.3212587941776623\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.3197720107578097\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.3058413767045545\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.3156117229926876\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.3283305612264895\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.3384844123340043\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3250997158843028\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.3109210906205353\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.3059966203930613\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.317465322442574\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.3223014462341383\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.6800270080566406\n",
      " and                       accuracy = 0.859375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8578816205263138\n",
      " and                       accuracy = 0.76171875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.7348100649459022\n",
      " and                       accuracy = 0.796875\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6607892081141472\n",
      " and                       accuracy = 0.8265625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7911974776249665\n",
      " and                       accuracy = 0.8067788481712341\n",
      "\n",
      "For epoch 23/30...\n",
      "66.023 minutes since training started\n",
      "Training loss = 1.3223014462341383\n",
      "Validation loss = 0.7911974776249665\n",
      "Accuracy = 0.8067788481712341\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 0\n",
      "Loss =             1.38504159450531\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.252122396772558\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.279383327279772\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.3288433724834072\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.341197718934315\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.3439480171484106\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.3389239868179696\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3389420064402298\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.3472129113880205\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.3470233790167085\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.3519315985169742\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.3488101745114742\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.685015082359314\n",
      " and                       accuracy = 0.875\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8521656841039658\n",
      " and                       accuracy = 0.7734375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.7295396008661815\n",
      " and                       accuracy = 0.8102678571428571\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6419124975800514\n",
      " and                       accuracy = 0.8375\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.8015173043196018\n",
      " and                       accuracy = 0.7956249988996066\n",
      "\n",
      "For epoch 24/30...\n",
      "68.881 minutes since training started\n",
      "Training loss = 1.3488101745114742\n",
      "Validation loss = 0.8015173043196018\n",
      "Accuracy = 0.7956249988996066\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.1889477968215942\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.357120318846269\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.3677459501084828\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.34445313484438\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.342222370752474\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.3308789367769278\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.331493344463286\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3208369184547746\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.3239145477612813\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.3241685746790288\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.321220846459417\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.314335202129142\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.7196893692016602\n",
      " and                       accuracy = 0.828125\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8463789969682693\n",
      " and                       accuracy = 0.7578125\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.691502530659948\n",
      " and                       accuracy = 0.8058035714285714\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6364841982722282\n",
      " and                       accuracy = 0.828125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7657033239419644\n",
      " and                       accuracy = 0.8076442296688373\n",
      "\n",
      "For epoch 25/30...\n",
      "71.745 minutes since training started\n",
      "Training loss = 1.314335202129142\n",
      "Validation loss = 0.7657033239419644\n",
      "Accuracy = 0.8076442296688373\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.491866111755371\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.2345701835372231\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.26931688615254\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.248370026388476\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.2502428104237813\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.2651559675441069\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.2646539015848128\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.2684115708713801\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.270916610588262\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.2824208998418116\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.2866456904033623\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.2923443207463015\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.5712324380874634\n",
      " and                       accuracy = 0.859375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.8037662357091904\n",
      " and                       accuracy = 0.7734375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.676482304930687\n",
      " and                       accuracy = 0.8058035714285714\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6387109890580177\n",
      " and                       accuracy = 0.825\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7850318149878428\n",
      " and                       accuracy = 0.791009614100823\n",
      "\n",
      "For epoch 26/30...\n",
      "74.601 minutes since training started\n",
      "Training loss = 1.2923443207463015\n",
      "Validation loss = 0.7850318149878428\n",
      "Accuracy = 0.791009614100823\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.2284471988677979\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.2581598921255632\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.2573013674645197\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.2714276256099823\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.299105200825668\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.3167752530060561\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.3054611204100437\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3265901291874094\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.3371594077275124\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.3290515096632989\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.3179441696346397\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.3155876542758016\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.5071287155151367\n",
      " and                       accuracy = 0.890625\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.7646714746952057\n",
      " and                       accuracy = 0.80859375\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.6874345775161471\n",
      " and                       accuracy = 0.8191964285714286\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6308017447590828\n",
      " and                       accuracy = 0.840625\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7402393829364043\n",
      " and                       accuracy = 0.8246153868161715\n",
      "\n",
      "For epoch 27/30...\n",
      "77.461 minutes since training started\n",
      "Training loss = 1.3155876542758016\n",
      "Validation loss = 0.7402393829364043\n",
      "Accuracy = 0.8246153868161715\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.2758679389953613\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.238613410429521\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.2307904674893333\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.253212805717222\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.2680140442964507\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.2792644547481162\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.2829302353937118\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.272165620830697\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.2655677515783428\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.2612302866610852\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.2646951699020839\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.267964510084356\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.602131187915802\n",
      " and                       accuracy = 0.859375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.7515329793095589\n",
      " and                       accuracy = 0.78515625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.6446996948548726\n",
      " and                       accuracy = 0.8169642857142857\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.5840939924120903\n",
      " and                       accuracy = 0.8453125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7144968131413827\n",
      " and                       accuracy = 0.8258173098930945\n",
      "\n",
      "For epoch 28/30...\n",
      "80.322 minutes since training started\n",
      "Training loss = 1.267964510084356\n",
      "Validation loss = 0.7144968131413827\n",
      "Accuracy = 0.8258173098930945\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.3477330207824707\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.248296938159249\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.2466279864311218\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.255086197007087\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.2410913429609158\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.2240804889622856\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.2332432201651276\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.2482097174080324\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.2385965718163385\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.2353519469827086\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.246921672089265\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.246947922174213\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.5722716450691223\n",
      " and                       accuracy = 0.859375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.7920719534158707\n",
      " and                       accuracy = 0.76171875\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.6746945785624641\n",
      " and                       accuracy = 0.796875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation batch 9\n",
      "Loss =                       0.6158048346638679\n",
      " and                       accuracy = 0.8234375\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7399712308095052\n",
      " and                       accuracy = 0.8077884637392484\n",
      "\n",
      "For epoch 29/30...\n",
      "83.184 minutes since training started\n",
      "Training loss = 1.246947922174213\n",
      "Validation loss = 0.7399712308095052\n",
      "Accuracy = 0.8077884637392484\n",
      "\n",
      "\n",
      "Training batch 0\n",
      "Loss =             1.1835381984710693\n",
      "\n",
      "Training batch 10\n",
      "Loss =             1.1859056082638828\n",
      "\n",
      "Training batch 20\n",
      "Loss =             1.2469160528410048\n",
      "\n",
      "Training batch 30\n",
      "Loss =             1.240409508828194\n",
      "\n",
      "Training batch 40\n",
      "Loss =             1.2999333433988618\n",
      "\n",
      "Training batch 50\n",
      "Loss =             1.3122370359944362\n",
      "\n",
      "Training batch 60\n",
      "Loss =             1.3094055945756005\n",
      "\n",
      "Training batch 70\n",
      "Loss =             1.3131182915727857\n",
      "\n",
      "Training batch 80\n",
      "Loss =             1.313626397539068\n",
      "\n",
      "Training batch 90\n",
      "Loss =             1.2991423312124315\n",
      "\n",
      "Training batch 100\n",
      "Loss =             1.2905626745507268\n",
      "\n",
      "Training batch 102\n",
      "Loss =             1.2882157622031796\n",
      "\n",
      "Validation batch 0\n",
      "Loss =                       0.48774415254592896\n",
      " and                       accuracy = 0.9375\n",
      "\n",
      "Validation batch 3\n",
      "Loss =                       0.7635567933320999\n",
      " and                       accuracy = 0.7890625\n",
      "\n",
      "Validation batch 6\n",
      "Loss =                       0.6664094179868698\n",
      " and                       accuracy = 0.8102678571428571\n",
      "\n",
      "Validation batch 9\n",
      "Loss =                       0.6219143405556679\n",
      " and                       accuracy = 0.828125\n",
      "\n",
      "Validation batch 12\n",
      "Loss =                       0.7444973737001419\n",
      " and                       accuracy = 0.8098557683137747\n",
      "\n",
      "For epoch 30/30...\n",
      "86.048 minutes since training started\n",
      "Training loss = 1.2882157622031796\n",
      "Validation loss = 0.7444973737001419\n",
      "Accuracy = 0.8098557683137747\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "from workspace_utils import keep_awake\n",
    "\n",
    "# Keep GPU session awake until done training\n",
    "for e in keep_awake(range(epochs)):\n",
    "    \n",
    "    # ---------------------- TRAINING ----------------------\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    training_batch_counter = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "\n",
    "        # Move input and label tensors to the GPU or CPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        # Monitor every 10 batches and final batch\n",
    "        if training_batch_counter % 10 == 0 or training_batch_counter == (len(trainloader) - 1):\n",
    "            print(f\"Training batch {training_batch_counter}\\nLoss = \\\n",
    "            {training_loss/(training_batch_counter + 1)}\\n\")\n",
    "            \n",
    "        training_batch_counter += 1\n",
    "        \n",
    "    # ---------------------- VALIDATION ----------------------\n",
    "    \n",
    "       \n",
    "    # turn off gradients for speedup in validation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set model to evaluation mode and remove un-needed things like Dropout layers\n",
    "        model.eval()\n",
    "      \n",
    "        accuracy = 0\n",
    "        valid_loss = 0\n",
    "        val_batch_counter = 0\n",
    "        \n",
    "        for images, labels in validloader:\n",
    "            # Move input and label tensors to the GPU or CPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            probs = torch.exp(outputs)\n",
    "\n",
    "            _, top_class = probs.topk(1, dim = 1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            # Monitor every 3 batches and final batch\n",
    "            if val_batch_counter % 3 == 0 or val_batch_counter == (len(validloader) - 1):\n",
    "                print(f\"Validation batch {val_batch_counter}\\nLoss = \\\n",
    "                      {valid_loss/(val_batch_counter + 1)}\\n and \\\n",
    "                      accuracy = {accuracy/(val_batch_counter + 1)}\\n\")\n",
    "            \n",
    "            val_batch_counter += 1\n",
    "            \n",
    "            \n",
    "    # Note that normalizing to train/validloader length is due to need to divide by batch size\n",
    "    # to effectively average the quantity in question\n",
    "    print(f\"For epoch {e+1}/{epochs}...\")\n",
    "    print(f\"{round((time()-t0)/60, 3)} minutes since training started\")\n",
    "    print(f\"Training loss = {training_loss/len(trainloader)}\")\n",
    "    print(f\"Validation loss = {valid_loss/len(validloader)}\")\n",
    "    print(f\"Accuracy = {accuracy/len(validloader)}\\n\\n\")\n",
    "    \n",
    "    # Save performance results across epochs\n",
    "    performance = pd.Series([e+1, training_loss/len(trainloader),\n",
    "                            valid_loss/len(validloader),\n",
    "                            accuracy/len(validloader)],\n",
    "                           index = performance_record.columns)\n",
    "    performance_record.append(performance, ignore_index = True, sort = False)\n",
    "    \n",
    "    # set model back to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Simple early stopping\n",
    "    #if accuracy/len(validloader) > 0.82: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For reference, Model 1 had an architecture of 3x hidden (2048 -> 1024 -> 512 -> 256 -> 102); all ReLU; no Dropout**\n",
    "\n",
    "<center> <b> Results of Different Model Runs </b> </center>\n",
    "\n",
    "Model ID | Deviation from Previous Models | Optimizer | Learning Rate | Number of Epochs | Validation Accuracy | Notes\n",
    "--- | --- | --- | --- | --- | --- | ---\n",
    "1 | N/A | Adam | 0.001 | 10 | 0.652 | \n",
    "2 | Added Dropout(0.2) on layers 2 and 3 | Adam | 0.001 | 10 | 0.645 | \n",
    "3 | Same as Model 2 | Adam | 0.01 | 10 | 0.06 | \n",
    "4 | Same as Model 2 | Adam | 0.005 | 10 | 0.06 | Stopped after 2 epochs\n",
    "5 | Same as Model 2 | Adam | 0.0005 | 10 | 0.723 | \n",
    "6 | Same as Model 2 | Adam | 0.0001 | 10 | 0.571 | \n",
    "7 | Same as Model 2 | Adam | 0.0005 | 30 | 0.810 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other items to consider in the future if we want to train this further**\n",
    "\n",
    "1. Add more hidden layers + dropout\n",
    "2. Try a different pretrained model (e.g. densenet)\n",
    "1. Check to see if other optimizers than Adam make sense to try out\n",
    "    * `optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, momentum=0.9)`\n",
    "    * `optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, nesterov = True)`\n",
    "4. Change the batch size (64 -> 128). Bigger batches + adaptive learning rates (such as those achieved with rmsprop) [allow you to avoid sampling error of mini-batches causing gradient sign changes that look meaningful but aren't](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "5. Change the data augmentation (maybe include a random selection/ordering transformation?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss = 0.8524104150441977\n",
      "Testing accuracy = 0.7742270001998315\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (hidden1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (activation1): ReLU()\n",
       "    (dropout1): Dropout(p=0.2)\n",
       "    (hidden2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (activation2): ReLU()\n",
       "    (dropout2): Dropout(p=0.2)\n",
       "    (hidden3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (activation3): ReLU()\n",
       "    (output): Linear(in_features=256, out_features=102, bias=True)\n",
       "    (activation_output): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "\n",
    "# ---------------------- TESTING ----------------------\n",
    "       \n",
    "# turn off gradients for speedup in testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    # set model to evaluation mode and remove un-needed things like Dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    for images, labels in testloader:\n",
    "        # Move input and label tensors to the GPU or CPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        probs = torch.exp(outputs)\n",
    "\n",
    "        _, top_class = probs.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "\n",
    "\n",
    "# Note that normalizing to train/validloader length is due to need to divide by batch size\n",
    "# to effectively average the quantity in question\n",
    "print(f\"Testing loss = {test_loss/len(testloader)}\")\n",
    "print(f\"Testing accuracy = {test_accuracy/len(testloader)}\\n\\n\")\n",
    "\n",
    "# set model back to train mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very nice! We see about 77.4% accuracy with this model!** Let's save this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T02:59:57.101699Z",
     "start_time": "2019-06-07T02:59:57.083611Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-29bc911013fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_to_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m checkpoint = {'layers': layers,\n\u001b[0m\u001b[1;32m      6\u001b[0m               \u001b[0;34m'model_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m              \u001b[0;34m'epoch_count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# Note that class_to_idx provides the mapping of my folder names to the index used in the model\n",
    "\n",
    "model.class_to_idx = cat_to_name\n",
    "\n",
    "checkpoint = {'layers': layers,\n",
    "              'model_state': model.state_dict(),\n",
    "             'epoch_count': epochs,\n",
    "             'opt_state': optimizer.state_dict(),\n",
    "             'class_to_idx': train_data.class_to_idx,\n",
    "             'idx_to_class': {v: k for k,v in train_data.class_to_idx.items()}}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoints/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T02:34:15.480470Z",
     "start_time": "2019-06-07T02:34:15.473426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports needed in case we're starting work from this point in the notebook\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath, device = 'cpu'):\n",
    "    '''\n",
    "    Loads your model fully in eval mode\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: str. Relative filepath from working directory to checkpoint.pth file\n",
    "    \n",
    "    device: str. Can be either 'cpu' or 'cuda:0'\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (model, optimizer) objects.\n",
    "    '''\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    model = models.inception_v3(pretrained=True)\n",
    "    \n",
    "    # Freeze parameters so we can't backprop through the pre-trained feature detector\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.fc = nn.Sequential(checkpoint['layers'])\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.0005)\n",
    "    optimizer.load_state_dict(checkpoint['opt_state'])\n",
    "    \n",
    "    model.to(torch.device(device))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T20:12:41.745259Z",
     "start_time": "2019-06-04T20:12:38.674797Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the model, as needed\n",
    "\n",
    "model, optimizer = load_checkpoint('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T20:12:43.900131Z",
     "start_time": "2019-06-04T20:12:43.882103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (hidden1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (activation1): ReLU()\n",
       "    (dropout1): Dropout(p=0.2)\n",
       "    (hidden2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (activation2): ReLU()\n",
       "    (dropout2): Dropout(p=0.2)\n",
       "    (hidden3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (activation3): ReLU()\n",
       "    (output): Linear(in_features=256, out_features=102, bias=True)\n",
       "    (activation_output): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T02:58:48.514674Z",
     "start_time": "2019-06-06T02:58:48.509528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0005\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T03:06:32.953063Z",
     "start_time": "2019-06-06T03:06:32.948119Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_resize(image, goal_size):\n",
    "    '''\n",
    "    Takes a PIL image and outputs the new dimensions it should have in a PyTorch-like\n",
    "    manner such that the shorter axis is set to goal_size and the long axis is scaled \n",
    "    such that the original aspect ratio is maintained. This is intended to be fed into\n",
    "    Image.resize().\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: PIL image object\n",
    "    \n",
    "    goal_size: int. Desired minimum dimension size.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of ints of the format (new width, new height)\n",
    "    '''\n",
    "    \n",
    "    aspect_ratio = min(image.size) / max(image.size)\n",
    "\n",
    "    # Get the index of the smaller dimension\n",
    "    min_ix = image.size.index(min(image.size))\n",
    "\n",
    "    # width is smaller than height\n",
    "    if min_ix == 0:\n",
    "        return (goal_size, int(goal_size/aspect_ratio))\n",
    "    else:\n",
    "        return (int(goal_size/aspect_ratio), goal_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T03:06:37.190693Z",
     "start_time": "2019-06-06T03:06:37.183160Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_centercrop_box(image, goal_size):\n",
    "    '''\n",
    "    Takes a PIL image and outputs the 4-tuple of coordinates needed to perform a centered cropping\n",
    "    of the image of size goal_size x goal_size. This is intended to be fed into Image.crop().\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: PIL image object\n",
    "    \n",
    "    goal_size: int. Desired resultant dimension size.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    4-tuple of ints coordinates of the format (new_width_X, new_width_Y \n",
    "                                                new_height_X, new_height_Y)\n",
    "    '''\n",
    "    \n",
    "    width = image.size[0]\n",
    "    height = image.size[1]\n",
    "    \n",
    "    # upperLeft_X, upperLeft_Y, lowerRight_X, lowerRight_Y\n",
    "    bound_box = [int(0.5*(width - goal_size)), int(0.5*(height - goal_size)),\n",
    "                int(0.5*(width + goal_size)), int(0.5*(height + goal_size))]\n",
    "    \n",
    "    # Check to make sure both dimensions produce goal_size\n",
    "    bound_box_w = bound_box[2] - bound_box[0]\n",
    "    bound_box_h = bound_box[3] - bound_box[1]\n",
    "    \n",
    "    if bound_box_w != goal_size:\n",
    "        bound_box[2] -= bound_box_w - goal_size\n",
    "    \n",
    "    \n",
    "    return tuple(bound_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T01:52:58.736064Z",
     "start_time": "2019-06-07T01:52:58.729222Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "    # Note that, in order to make this similar to my validation and testing batches,\n",
    "    # I actually need to resize to 512x512 and then crop to 299x299 pixels\n",
    "    \n",
    "    # Resize to 512 on the shortest axis, keeping aspect ratio\n",
    "    new_size = calculate_resize(image, 512)\n",
    "    image = image.resize(new_size)   \n",
    "    \n",
    "    \n",
    "    # Center-crop the image to 299x299\n",
    "    crop_size = calculate_centercrop_box(image, 299)\n",
    "    image = image.crop(crop_size)\n",
    "    \n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    np_image = np.array(image)\n",
    "    \n",
    "    # Scale 0-255 color channel values to 0-1\n",
    "    np_image = np.divide(np_image, np.array([255]))\n",
    "    \n",
    "    # Normalize color channel values\n",
    "    MEANS = np.array([0.485, 0.456, 0.406])\n",
    "    STDEVS = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    np_image = np.subtract(np_image, MEANS)\n",
    "    np_image = np.divide(np_image, STDEVS)\n",
    "    \n",
    "    # Move color dimension from third to first place, retaining other two dimensions' orders\n",
    "    # Resulting array should be of shape (3,299,299)\n",
    "    np_image = np_image.transpose(2,0,1)\n",
    "    \n",
    "    # Return numpy array\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T01:43:39.254612Z",
     "start_time": "2019-06-07T01:43:39.248544Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T01:53:17.830509Z",
     "start_time": "2019-06-07T01:53:17.562448Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12412e940>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.open('data/test/5/image_05159.jpg')\n",
    "\n",
    "# Preprocess the image\n",
    "im = torch.Tensor(process_image(image))\n",
    "\n",
    "imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:10:28.166822Z",
     "start_time": "2019-06-07T03:10:28.157868Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5, device='cpu'):\n",
    "    ''' \n",
    "    Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: str. Filepath for image being classified\n",
    "    \n",
    "    model: PyTorch model\n",
    "    \n",
    "    topk: int. Indicates how many of the highest-probability classes you want predict()\n",
    "            to return\n",
    "            \n",
    "    device: str. Either 'cpu' or 'cuda:0'. Dictates if you'll be using the GPU to predict or the CPU\n",
    "            Note that prediction is pretty efficient, so no real need to use GPU.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    tuple of form (top_probabilities, top_class_labels)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # Load the Image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    np_data = process_image(image)\n",
    "    \n",
    "    \n",
    "    # PyTorch expects a 4D tensor for input into Conv2d layers, with a size-1\n",
    "    # first dimension. Not entirely sure what it is, but probably the batch ID.\n",
    "    # So let's just give it a new dimension with nothing in it and hope for the best!\n",
    "    dims = (1,) + np_data.shape\n",
    "    data = torch.Tensor(np_data).view(dims).to(device)\n",
    "    \n",
    "    # TODO: make it so moving of models and inputs to 'device' is done only here,\n",
    "        # not in earlier load_checkpoint() function\n",
    "    \n",
    "    #print(f\"Shape of input data is {data.shape}\")\n",
    "    \n",
    "    # Feedforward the image input to generate prediction probabilities\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set model to evaluation mode and remove un-needed things like Dropout layers\n",
    "        model.eval()\n",
    "        \n",
    "        outputs = model(data)\n",
    "        probs = torch.exp(outputs)\n",
    "\n",
    "    top_ps, top_idx = probs.topk(topk, dim = 1)\n",
    "    \n",
    "    # Convert to lists for iterating\n",
    "    top_ps = list(top_ps.numpy()[0])\n",
    "    top_idx = list(top_idx.numpy()[0])\n",
    "    \n",
    "    # Cast labels to strings for easy referencing in model.class_to_idx\n",
    "    idx_to_class = {v: k for k,v in test_data.class_to_idx.items()}\n",
    "    top_classes = [idx_to_class[idx] for idx in top_idx]\n",
    "        \n",
    "    return top_ps, top_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:10:36.359746Z",
     "start_time": "2019-06-07T03:10:36.065734Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30039874, 0.13981524, 0.10155622, 0.09249932, 0.06175754]\n",
      "['35', '92', '1', '29', '77']\n"
     ]
    }
   ],
   "source": [
    "probs, classes = predict('data/test/1/image_06743.jpg', model, device = 'cpu')\n",
    "print(probs)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uhhhh...what? 10% probability that this is class zero when that's not a label??**\n",
    "\n",
    "Glad we're not getting runtime errors anymore, but something is clearly still wrong..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display an image along with the top 5 classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "910px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
